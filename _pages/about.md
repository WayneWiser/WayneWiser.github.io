---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Quandong is a senior algorithm engineer and researcher at Xiaomi AI Lab. 
His research focuses on
multi-channel / end-to-end speech recognition, speech enhancement, speech separation, and multimodal modeling.
He is passionate about advancing far-field speech processing technologies and solving key problems. 
He has a vision of opening the door to the ultimate natural voice experience in the era of the Internet of Things, 
where there would not exist any obstacles to human-machine and human-human communication.

Prior to joining Xiaomi, Quandong received his Ph.D. degrees in
[Signal and Information Proccessing] 
from [Institute of Acoustics, Chinese Academy of Sciences]/[University of Chinese Academy of Sciences] in 2019.
During the Ph.D. period, he was also a joint training Ph.D. student at Georgia Institute of Technology
under the supervision of [Prof. Chin-Hui Lee] (https://chl.ece.gatech.edu/). He received
his B.S. degree in [Electrical Engineering] from
[Harbin Engineering University] in 2014.


## Recent Research Highlight

* [Audio-Visual
  HuBERT](https://ai.facebook.com/blog/ai-that-understands-speech-by-looking-as-well-as-hearing/):
  the first self-supervised model for audio-visual speech, achieving
  state-of-the-art performance on lip-reading, speech recognition, and
  audio-visual speech recognition with much less labeled data
* [data2vec](https://ai.facebook.com/blog/the-first-high-performance-self-supervised-algorithm-that-works-for-speech-vision-and-text/):
  The first high-performance self-supervised algorithm that works for speech,
  vision, and text
* [Textless Speech-to-Speech Translation on Real
  Data](https://arxiv.org/abs/2112.08352): first ever text-free
  speech-to-speech translation model trained on real data that 
  is on par with text-based models
* [wav2vec-U](https://ai.facebook.com/blog/wav2vec-unsupervised-speech-recognition-without-supervision/):
  an unsupervised speech recognition framework that rivals the best supervised 
  model from 2 years ago and works for 10 languages
* [Textless NLP](https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio/):
  a model that can do prompted or unprompted speech generation without using
  any text (like audio-version of
  [GPT-2](https://openai.com/blog/better-language-models/))
* [HuBERT](https://ai.facebook.com/blog/hubert-self-supervised-representation-learning-for-speech-recognition-generation-and-compression/):
  a state-of-the-art self-supervised speech representation learning model for 
  recognition, generation, and compression.
